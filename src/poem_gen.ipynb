{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "poem_gen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nredick/mais-hacks-2021/blob/main/src/poem_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abvMGmarSbYO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9iXek9U1Wtf"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/nredick/mais-hacks-2021/textgen/data/poemdataset/_sortedpoems.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import numpy as np \n",
        "import random"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnDnCW-Z7qv"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "data = open('_sortedpoems.txt', 'r+').readlines()\n",
        "\n",
        "corpus = [line.lower() for line in data][:20000]\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)\n",
        "\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/data/tokenizer.pkl',\"wb\") as f:\n",
        "  pickle.dump(tokenizer,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ9jS5Orea75"
      },
      "source": [
        "Get a sense of the corpus and the lengths of each line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb1NyjjxggXJ"
      },
      "source": [
        "print(len(corpus))\n",
        "print(len(tokenizer.texts_to_sequences(corpus[0])))\n",
        "print(len(tokenizer.texts_to_sequences(corpus[1])))\n",
        "print(len(tokenizer.texts_to_sequences(corpus[2])))\n",
        "print(len(tokenizer.texts_to_sequences(corpus[3])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHRSelcbee4U"
      },
      "source": [
        "Preprocessing the data and creating the training vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soPGVheskaQP"
      },
      "source": [
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLHDXG9TemXX"
      },
      "source": [
        "See the vocabulary and maximum sentence length. All vectors are padded (from the left) to match this length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4myRpB1c4Gg"
      },
      "source": [
        "print(tokenizer.word_index)\n",
        "print(max_sequence_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh3EOm0xetyq"
      },
      "source": [
        "Create the model and train it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9vH8Y59ajYL"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(80)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "adam = Adam(learning_rate=0.001)\n",
        "earlystop = EarlyStopping(monitor='val_accuracy', \n",
        "                          min_delta=0, \n",
        "                          patience=10, \n",
        "                          verbose=0, \n",
        "                          mode='auto')\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=adam, \n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(xs, \n",
        "                    ys, \n",
        "                    epochs=50, \n",
        "                    verbose=1,\n",
        "                    validation_split=0.15,\n",
        "                    callbacks=[earlystop], # stop after no improvement in validation accuracy\n",
        "                    )\n",
        "acc = round(history.history['accuracy'][-1],4)\n",
        "vacc = round(history.history['val_accuracy'][-1],4)\n",
        "epochs = history.params['epochs']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdnuWhPwe15d"
      },
      "source": [
        "Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOXY5lgf6pUo"
      },
      "source": [
        "tf.keras.models.save_model(model, f'/content/drive/MyDrive/data/model_tacc-{acc}_vacc-{vacc}_epochs-{epochs}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKJ6ZrOue2uG"
      },
      "source": [
        "Sample code to load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzd3rjbP9Yad"
      },
      "source": [
        "loaded_model = tf.keras.models.load_model(f'/content/drive/MyDrive/data/model_tacc-{acc}_vacc-{vacc}_epochs-{epochs}')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YXGelKThoTT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKeDJ-gWe7gX"
      },
      "source": [
        "Visualize the training and validation accuracy tradeoffs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poeprYK8h-c7"
      },
      "source": [
        "plot_graphs(history, 'accuracy')\n",
        "plot_graphs(history, 'val_accuracy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89sh70H7fAHI"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vc6PHgxa6Hm"
      },
      "source": [
        "# these repeated import statements are unnecessary, just to show what one would need\n",
        "# when running it in Flask\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "seed_text = \"dream cloud cheese\" # edit this to generate new poems!\n",
        "saved_model_path = 'f/content/drive/MyDrive/data/sortedmodel_tacc-{acc}_vacc-{vacc}_epochs-{epochs}'\n",
        "loaded_model = tf.keras.models.load_model(saved_model_path)\n",
        "tokenizer = pickle.load(open('/content/drive/MyDrive/data/tokenizer.pkl','rb'))\n",
        "max_sequence_len=75 # make sure to edit this if it changes\n",
        "\n",
        "def line_breaker(s):\n",
        "\t\"\"\" breaks string s into lines mostly randomly\"\"\"\n",
        "\ts = s.split()\n",
        "\tl=len(s) # len of string\n",
        "\toutput=\"\"\n",
        "\twhile l>0:\n",
        "\t\tx=random.randint(1,int(l/2)+1)\n",
        "\t\ttmp = s[:x]\n",
        "\t\toutput += ' '.join(tmp) + \"\\n\"\n",
        "\t\ts=s[x:]\n",
        "\t\tl -= x\n",
        "\t# line breaking between repeated words\n",
        "\tsplit = output.split(' ')\n",
        "\tfinal = \"\"\n",
        "\tfor i in range(len(split)-1):\n",
        "\t\tif split[i]==split[i+1]:\n",
        "\t\t\tfinal += split[i] + '\\n'\n",
        "\t\telse: \n",
        "\t\t\tfinal += split[i] + ' '\n",
        "\tif split[-2]==split[-1]:\n",
        "\t\tfinal += \"\\n\"+split[-1]\n",
        "\telse:\n",
        "\t\tfinal +=split[-1]\n",
        "\tfinal_output = final[0].upper()+final[1:]\n",
        "\treturn final_output  \n",
        "\n",
        "def pred_poem(seed_text,next_words=30,incl_title=True,):\n",
        "\tog_seed = seed_text\n",
        "\tfor _ in range(next_words):\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\tpredicted = np.argmax(loaded_model.predict(token_list), axis=-1)\n",
        "\t\toutput_word = \"\"\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == predicted:\n",
        "\t\t\t\toutput_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\tseed_text += \" \" + output_word\n",
        "\tif not incl_title:\n",
        "\t\tseed_text = seed_text[len(og_seed)+1:]\n",
        "\treturn line_breaker(seed_text)\n",
        "\n",
        "print(pred_poem(seed_text))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}